{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/ahmadbasha/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ahmadbasha/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "nltk.download('brown')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The brown Fox is quick and he is jumping over the lazy dog ! \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('brown', 'JJ'),\n",
       " ('Fox', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('quick', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('he', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('jumping', 'VBG'),\n",
       " ('over', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('lazy', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags = nltk.pos_tag(sentence.split())\n",
    "pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>brown</td>\n",
       "      <td>Fox</td>\n",
       "      <td>is</td>\n",
       "      <td>quick</td>\n",
       "      <td>and</td>\n",
       "      <td>he</td>\n",
       "      <td>is</td>\n",
       "      <td>jumping</td>\n",
       "      <td>over</td>\n",
       "      <td>the</td>\n",
       "      <td>lazy</td>\n",
       "      <td>dog</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNP</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>PRP</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VBG</td>\n",
       "      <td>IN</td>\n",
       "      <td>DT</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1    2    3      4    5    6    7        8     9    10    11   12  \\\n",
       "0  The  brown  Fox   is  quick  and   he   is  jumping  over  the  lazy  dog   \n",
       "1   DT     JJ  NNP  VBZ     JJ   CC  PRP  VBZ      VBG    IN   DT    JJ   NN   \n",
       "\n",
       "  13  \n",
       "0  !  \n",
       "1  .  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pos_tags).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy text \n",
    "txt = '''Sukanya, Bhupen and Uday are my good friends. Sukanya is getting married next year. Marriage is a big step in one’s life.  \n",
    "       It is both exciting and frightening. But friendship is a sacred bond between people. \n",
    "       It is a special kind of love between us.\n",
    "       Many of you must have tried searching for a friend but never found the right one.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize , sent_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "tokenized = sent_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sukanya, Bhupen and Uday are my good friends.',\n",
       " 'Sukanya is getting married next year.',\n",
       " 'Marriage is a big step in one’s life.',\n",
       " 'It is both exciting and frightening.',\n",
       " 'But friendship is a sacred bond between people.',\n",
       " 'It is a special kind of love between us.',\n",
       " 'Many of you must have tried searching for a friend but never found the right one.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "punc = list(string.punctuation)\n",
    "punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sukanya', 'NNP'), ('Bhupen', 'NNP'), ('Uday', 'NNP'), ('good', 'JJ'), ('friends', 'NNS')]\n",
      "[('Sukanya', 'NNP'), ('getting', 'VBG'), ('married', 'VBN'), ('next', 'JJ'), ('year', 'NN')]\n",
      "[('Marriage', 'NN'), ('big', 'JJ'), ('step', 'NN'), ('one', 'CD'), ('’', 'NN'), ('life', 'NN')]\n",
      "[('It', 'PRP'), ('exciting', 'VBG'), ('frightening', 'VBG')]\n",
      "[('But', 'CC'), ('friendship', 'NN'), ('sacred', 'VBD'), ('bond', 'NN'), ('people', 'NNS')]\n",
      "[('It', 'PRP'), ('special', 'JJ'), ('kind', 'NN'), ('love', 'VB'), ('us', 'PRP')]\n",
      "[('Many', 'JJ'), ('must', 'MD'), ('tried', 'VB'), ('searching', 'VBG'), ('friend', 'NN'), ('never', 'RB'), ('found', 'VBD'), ('right', 'RB'), ('one', 'CD')]\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')\n",
    "for i in tokenized: \n",
    "      \n",
    "    # Word tokenizers is used to find the words  \n",
    "    # and punctuation in a string \n",
    "    wordsList = nltk.word_tokenize(i) \n",
    "  \n",
    "    # removing stop words from wordList \n",
    "    wordsList = [w for w in wordsList if w not in stop_words + punc]  \n",
    "  \n",
    "    #  Using a Tagger. Which is part-of-speech  \n",
    "    # tagger or POS-tagger.  \n",
    "    tagged = nltk.pos_tag(wordsList) \n",
    "\n",
    "    \n",
    "    print(tagged)\n",
    "    # if tagged[0][1] == 'NNP':\n",
    "    #   print(tagged[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sukanya\n",
      "Bhupen\n",
      "Uday\n",
      "Sukanya\n"
     ]
    }
   ],
   "source": [
    "for i in tokenized: \n",
    "      \n",
    "    # Word tokenizers is used to find the words  \n",
    "    # and punctuation in a string \n",
    "    wordsList = nltk.word_tokenize(i) \n",
    "  \n",
    "    # removing stop words from wordList \n",
    "    wordsList = [w for w in wordsList if w not in stop_words + punc]  \n",
    "  \n",
    "    #  Using a Tagger. Which is part-of-speech  \n",
    "    # tagger or POS-tagger.  \n",
    "    tagged = nltk.pos_tag(wordsList) \n",
    "\n",
    "    \n",
    "#     print(tagged)\n",
    "    for i in tagged:\n",
    "        if i[1] == 'NNP':\n",
    "            print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Many', 'JJ'),\n",
       " ('must', 'MD'),\n",
       " ('tried', 'VB'),\n",
       " ('searching', 'VBG'),\n",
       " ('friend', 'NN'),\n",
       " ('never', 'RB'),\n",
       " ('found', 'VBD'),\n",
       " ('right', 'RB'),\n",
       " ('one', 'CD')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were thirty-eight patients on the bus the morning I left for Hanover , most of them disturbed and hallucinating .\n",
      "An interne , a nurse and two attendants were in charge of us .\n",
      "I felt lonely and depressed as I stared out the bus window at Chicago's grim , dirty West Side .\n",
      "It seemed incredible , as I listened to the monotonous drone of voices and smelled the fetid odors coming from the patients , that technically I was a ward of the state of Illinois , going to a hospital for the mentally ill .\n",
      "I suddenly thought of Mary Jane Brennan , the way her pretty eyes could flash with anger , her quiet competence , the gentleness and sweetness that lay just beneath the surface of her defenses .\n",
      "We had become good friends during my stay at Cook County Hospital .\n",
      "I had told her enough about myself to offset somewhat the damaging stories that had appeared in local newspapers after my little adventure in Marshall Field & Co. .\n",
      "She knew that I lived at a good address on the Gold Coast , that I had once been a medical student and was thinking of returning to the university to finish my medical studies .\n",
      "She knew also that I was unmarried and without a single known relative .\n",
      "She wasn't quite sure that I felt enough remorse about my drinking , or that I would not return to it once I was out and on my own again .\n",
      "This had worried her .\n",
      "`` I read those newspaper stories about you '' , she had said .\n",
      "`` You must have loved that girl very much , but you couldn't have meant it when you said that you wanted to kill her '' .\n",
      "`` Why do you say that '' ? ?\n",
      "I asked .\n",
      "`` I was full of booze and , well , a drunk is apt to do anything he says he'll do '' .\n",
      "Nonsense ! !\n",
      "I grew up in an Irish neighborhood on Chicago's West Side .\n",
      "Don't tell me about drunks .\n",
      "You're not the kind to go violent .\n"
     ]
    }
   ],
   "source": [
    "for i in brown.sents(categories='mystery')[:20]:\n",
    "    print(\" \".join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There',\n",
       " 'were',\n",
       " 'thirty-eight',\n",
       " 'patients',\n",
       " 'on',\n",
       " 'the',\n",
       " 'bus',\n",
       " 'the',\n",
       " 'morning',\n",
       " 'I',\n",
       " 'left',\n",
       " 'for',\n",
       " 'Hanover',\n",
       " ',',\n",
       " 'most',\n",
       " 'of',\n",
       " 'them',\n",
       " 'disturbed',\n",
       " 'and',\n",
       " 'hallucinating',\n",
       " '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.sents(categories='mystery')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['There', 'were', 'thirty-eight', 'patients', 'on', 'the', 'bus', 'the', 'morning', 'I', 'left', 'for', 'Hanover', ',', 'most', 'of', 'them', 'disturbed', 'and', 'hallucinating', '.'], ['An', 'interne', ',', 'a', 'nurse', 'and', 'two', 'attendants', 'were', 'in', 'charge', 'of', 'us', '.'], ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized sentences\n",
    "brown.sents(categories='mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('There', 'EX'), ('were', 'BED'), ('thirty-eight', 'CD'), ('patients', 'NNS'), ('on', 'IN'), ('the', 'AT'), ('bus', 'NN'), ('the', 'AT'), ('morning', 'NN'), ('I', 'PPSS'), ('left', 'VBD'), ('for', 'IN'), ('Hanover', 'NP'), (',', ','), ('most', 'AP'), ('of', 'IN'), ('them', 'PPO'), ('disturbed', 'VBN'), ('and', 'CC'), ('hallucinating', 'VBG'), ('.', '.')], [('An', 'AT'), ('interne', 'NN'), (',', ','), ('a', 'AT'), ('nurse', 'NN'), ('and', 'CC'), ('two', 'CD'), ('attendants', 'NNS'), ('were', 'BED'), ('in', 'IN'), ('charge', 'NN'), ('of', 'IN'), ('us', 'PPO'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tagged sentences\n",
    "brown.tagged_sents(categories='mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57169"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get tagged words\n",
    "tagged_words = brown.tagged_words(categories='mystery')\n",
    "len(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('There', 'EX'),\n",
       " ('were', 'BED'),\n",
       " ('thirty-eight', 'CD'),\n",
       " ('patients', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('bus', 'NN'),\n",
       " ('the', 'AT'),\n",
       " ('morning', 'NN'),\n",
       " ('I', 'PPSS'),\n",
       " ('left', 'VBD'),\n",
       " ('for', 'IN'),\n",
       " ('Hanover', 'NP'),\n",
       " (',', ','),\n",
       " ('most', 'AP'),\n",
       " ('of', 'IN'),\n",
       " ('them', 'PPO'),\n",
       " ('disturbed', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('hallucinating', 'VBG')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('left', 'VBD'),\n",
       " ('disturbed', 'VBN'),\n",
       " ('hallucinating', 'VBG'),\n",
       " ('felt', 'VBD'),\n",
       " ('depressed', 'VBD'),\n",
       " ('stared', 'VBD'),\n",
       " ('seemed', 'VBD'),\n",
       " ('listened', 'VBD'),\n",
       " ('smelled', 'VBD'),\n",
       " ('coming', 'VBG')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get nouns from tagged words\n",
    "# nouns = [(word, tag) for word, tag in tagged_words if tag in ['NNP', 'NN']]\n",
    "\n",
    "verbs = [(word, tag) for word, tag in tagged_words if 'VB' in tag]\n",
    "\n",
    "\n",
    "# nouns[0:10] # view the first 10 nouns\n",
    "verbs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 1961 samples and 6962 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('said', 202),\n",
       " ('get', 95),\n",
       " ('know', 86),\n",
       " ('go', 80),\n",
       " ('see', 79),\n",
       " ('got', 77),\n",
       " ('went', 77),\n",
       " ('going', 66),\n",
       " ('knew', 65),\n",
       " ('made', 60),\n",
       " ('come', 55),\n",
       " ('think', 54),\n",
       " ('told', 52),\n",
       " ('looked', 52),\n",
       " ('turned', 51),\n",
       " ('want', 50),\n",
       " ('came', 50),\n",
       " ('take', 48),\n",
       " ('put', 48),\n",
       " ('took', 47)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build frequency distribution for nouns\n",
    "freq = nltk.FreqDist([word for word, tag in verbs])\n",
    "\n",
    "print(freq)\n",
    "\n",
    "# view top 10 occuring nouns\n",
    "freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
